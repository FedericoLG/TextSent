{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features for text sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv('data/yelp_example_1_small.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms and term frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "rows = tqdm_notebook(list(D.iterrows()))\n",
    "for i, row in rows:\n",
    "    doc = nlp(row.content)\n",
    "    for s, sent in enumerate(doc.sents):\n",
    "        for t, token in enumerate(sent):\n",
    "            record = {'doc': i, 'sentence': s, 'position': t}\n",
    "            record['token'] = token.text\n",
    "            record['lower'] = token.text.lower()\n",
    "            record['lemma'] = token.lemma_\n",
    "            record['pos'] = token.pos_\n",
    "            record['alpha'] = token.is_alpha\n",
    "            record['stop'] = token.is_stop\n",
    "            record['doc_size'] = len(doc)\n",
    "            record['sentence_size'] = len(sent)\n",
    "            records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient()['textsent']\n",
    "yelp = db['yelp_simple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'$match': {'pos': {'$in': ['NOUN', 'ADJ']}}}\n",
    "p = {'$project': {'_id': 0, 'doc': 1, 'sentence': 1, 'position': 1, 'lemma': 1}}\n",
    "s = {'$sort': {'doc': 1, 'sentence': 1}}\n",
    "g = {'$group': {'_id': '$doc', 'tokens': {'$push': '$lemma'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in yelp.aggregate([m, p, s, g], allowDiskUse=True):\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'$match': {'pos': {'$in': ['NOUN', 'ADJ']}}}\n",
    "g = {'$group': {'_id': {'doc': '$doc', 'size': '$doc_size', 'lemma': '$lemma'}, 'tf': {'$sum': 1}}}\n",
    "h = {'$match': {'tf': {'$gte': 3}}}\n",
    "s = {'$sort': {'tf': -1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'$match': {'pos': {'$in': ['NOUN', 'ADJ']}}}\n",
    "g = {'$group': {'_id': '$lemma', 'docs': {'$addToSet': '$doc'}}}\n",
    "p = {'$project': {'_id': 1, 'docs': {'$size': '$docs'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(yelp.distinct('doc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in yelp.aggregate([m, g, p], allowDiskUse=True):\n",
    "    print(record['_id'], np.log(N / record['docs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sentiment lexicon to the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with the logical structure of sentences\n",
    "### Take into account negation using a dependency parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
