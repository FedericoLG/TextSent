{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f78e978",
   "metadata": {},
   "source": [
    "# Introduction to statistical language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b807f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481cfdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9416c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498aad50",
   "metadata": {},
   "source": [
    "## Empathetic dialogues\n",
    "Provides promts and utterances from dialogues in different emotional contexts.\n",
    "[Dataset link](https://huggingface.co/datasets/empathetic_dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1564af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fca924e7a84f859bca5464fd131f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"empathetic_dialogues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6919becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7cf7782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>2</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Was this a friend you were in love with_comma_...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx      context  \\\n",
       "0  hit:0_conv:1              1  sentimental   \n",
       "1  hit:0_conv:1              2  sentimental   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...            1   \n",
       "1  I remember going to the fireworks with my best...            0   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5       \n",
       "1  Was this a friend you were in love with_comma_...  5|5|5_2|2|5       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72037c2c",
   "metadata": {},
   "source": [
    "# Language model of emotional contexts\n",
    "In this example, we try to build a LM for each of the emotional contexts, in order to explore three main aspects of LMs:\n",
    "- how word prediction changes with different models\n",
    "- how a model can be used to generate a text\n",
    "- how a model can be used to classify a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13bd6dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sentimental', 'afraid', 'proud', 'faithful', 'terrified',\n",
       "       'joyful', 'angry', 'sad', 'jealous', 'grateful', 'prepared',\n",
       "       'embarrassed', 'excited', 'annoyed', 'lonely', 'ashamed', 'guilty',\n",
       "       'surprised', 'nostalgic', 'confident', 'furious', 'disappointed',\n",
       "       'caring', 'trusting', 'disgusted', 'anticipating', 'anxious',\n",
       "       'hopeful', 'content', 'impressed', 'apprehensive', 'devastated'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.context.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c82fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76673, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d269febb",
   "metadata": {},
   "source": [
    "## Documents tokenizer and padding\n",
    "Padding is a strategy for ensuring sentences have the same size in terms of tokens by adding a special padding token to shorter sentences.\n",
    "\n",
    "Note that BERT tokenizers have a maximum sequence length. Thus, we need to split the text composed by more then the maximum number of chars.\n",
    "\n",
    "We create a unique dataset of text blocks and we keep an index of the corresponding emotion.\n",
    "\n",
    "We also exploit the capability of BERT to tokenize pair of sentences. See [https://huggingface.co/transformers/v3.0.2/preprocessing.html](https://huggingface.co/transformers/v3.0.2/preprocessing.html)\n",
    "\n",
    "**Summary of our pre-processing strategy**\n",
    "- we keep the prompt as is\n",
    "- we split the utterance in several sentences\n",
    "- for each utterance sentence, we create a pair (prompt, sentence)\n",
    "- we tokenize the pair by **Padding** and **Truncating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ab27568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dec33c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9746b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, prompts, utterances = X.context.values, X.prompt.values, X.utterance.values\n",
    "batch_prompts, batch_utterances, batch_contexts = [], [], []\n",
    "\n",
    "for i, c in enumerate(contexts):\n",
    "    p, u = prompts[i], utterances[i]\n",
    "    batch_prompts.append(p)\n",
    "    batch_utterances.append(u)\n",
    "    batch_contexts.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace49608",
   "metadata": {},
   "source": [
    "### Balance and filter\n",
    "Here, we compose a dataset by selecting sample of emotional contexts, in order to ensure balance and keep the example simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09eeb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f39f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76673\n"
     ]
    }
   ],
   "source": [
    "emotions = pd.DataFrame(Counter(batch_contexts).most_common())#.head(6)\n",
    "E = set(emotions[0])\n",
    "sample_prompts, sample_utterances, sample_contexts = [], [], []\n",
    "for i, c in enumerate(batch_contexts):\n",
    "    if c in E:\n",
    "        sample_contexts.append(c)\n",
    "        sample_prompts.append(batch_prompts[i])\n",
    "        sample_utterances.append(batch_utterances[i])\n",
    "print(len(sample_contexts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dcdd79",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9349a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(\n",
    "    sample_prompts, sample_utterances, truncation=True, padding=True)['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e14b5",
   "metadata": {},
   "source": [
    "### Show the first 6 tokens of a sentence and how the decoder works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "635171a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world. I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people_comma_ we felt like the only people in the world. \n",
      "\n",
      "tokens => [101, 146, 2676, 1280, 1106, 1103]\n",
      "decoded => [CLS] I remember going to the fireworks with my best friend. There was a lot of people _ comma _ but it only felt like us in the world. [SEP] I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people _ comma _ we felt like the only people in the world. [SEP] [PAD] [PAD]  ...\n"
     ]
    }
   ],
   "source": [
    "sentence_id = 0\n",
    "print(sample_prompts[sentence_id], sample_utterances[sentence_id], '\\n')\n",
    "print('tokens', '=>', encoded_inputs[sentence_id][:6])\n",
    "decoded_text = tokenizer.decode(encoded_inputs[sentence_id])\n",
    "print('decoded', '=>', decoded_text[:decoded_text.index('[PAD]')+12], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfc05a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(encoded_text):\n",
    "    decoded_text = tokenizer.decode(encoded_text)\n",
    "    if '[PAD]' in decoded_text:\n",
    "        text = decoded_text[:decoded_text.index('[PAD]')+12]\n",
    "    else:\n",
    "        text = decoded_text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13954f96",
   "metadata": {},
   "source": [
    "### Create sub-corpora for emotional clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c66681f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {\n",
    "    'Profile A': {'caring', 'nostalgic', 'sentimental'},\n",
    "    'Profile B': {'angry', 'disappointed', 'furious'},\n",
    "    'Profile C': {'content', 'excited', 'grateful'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3675274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(emotions, contexts, encoded_docs):\n",
    "    data = []\n",
    "    for i, context in enumerate(contexts):\n",
    "        if context in emotions:\n",
    "            data.append(encoded_docs[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "699649ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = dict([\n",
    "    (profile, get_corpus(emotions[profile], sample_contexts, encoded_inputs)) for profile in emotions.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "010edd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile A 6477\n",
      "Profile B 7490\n",
      "Profile C 7637\n"
     ]
    }
   ],
   "source": [
    "for k, v in corpora.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b21346e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 146, 2676, 1280]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora['Profile A'][0][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ee9ef",
   "metadata": {},
   "source": [
    "## Statistical language models: n-gram models\n",
    "\n",
    "A n-gram is a chunk of consecutive words.\n",
    "    \n",
    "    * unigrams:  time, flies, like, an, arrow\n",
    "    * bigrams:   (time, flies), (flies, like), (like, an), (an, arrow)\n",
    "    * trigrams:  (time, flies, like), (flies, like, an), (like, an, arrow)\n",
    "    * 4-grams:   (time, flies, like, an), (flies, like, an, arrow)\n",
    "\n",
    "N-gram language model estimates conditional probability of the next word\n",
    "by collecting n-gram counts from a text corpus.\n",
    "\n",
    "$$ P(w_{t+1}| w_1, .., w_{t} ) = \\frac{count (w_1, .., w_{t}, w_{t+1})}{count( w_1, .., w_{t})}  $$\n",
    "\n",
    "\n",
    "**Simplifying assumption**\n",
    "\n",
    "The n-gram model assumes that the probability of a word (gram) depends only on preceding n - 1 words.\n",
    "A 3-gram language model approximates conditional probabilities as follows:\n",
    "\n",
    "$$ P(\\text{ Time flies like an arrow} ) \n",
    "= P(\\text{ Time } ) · P(\\text{ flies }|\\text{ Time } ) · P(\\text{ like }| \\text{ Time flies }) · P(\\text{ an } | \\text{  flies like } ) · P(\\text{ arrow } | \\text{ like an } ) $$\n",
    "\n",
    "\n",
    "**Smoothing and backoff**\n",
    "\n",
    "Cases of zeros at denominator or numerator: \n",
    "* Avoid zeros in the numerator, by adding 1, or some small quantity to all ngram counts. (laplace smoothing)\n",
    "  Smoothing is used to give some probability to unseen ngrams.  \n",
    "* If a prefix has not been observed, a zero at denominator will prevent you from computing the probability:\n",
    "  the only solution is to backoff to shorter ngram prefix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e6a406",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03d61ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import NGramModel\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc9eeca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, None, 101), (None, 101, 2903), (101, 2903, 143), (2903, 143, 245)]\n"
     ]
    }
   ],
   "source": [
    "example = [101, 2903, 143, 245]\n",
    "print(list(ngrams(example, n=3, pad_left=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7abcda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 6477/6477 [00:00<00:00, 30861.67it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = corpora['Profile A']\n",
    "profile_models = NGramModel(n=3)\n",
    "profile_models.count_ngrams([[x for x in y if x != 0] for y in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb718c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165 when -1.0213964380007265\n",
      "1103 the -1.9832976811269338\n",
      "1139 my -2.070309058116563\n",
      "1155 all -3.244428899292818\n",
      "1280 going -3.244428899292818\n"
     ]
    }
   ],
   "source": [
    "prefix = tokenizer('I remember')['input_ids'][:-1]\n",
    "log_p = pd.Series(profile_models.compute_log_prob(prefix))\n",
    "for k, v in log_p.sort_values(ascending=False).head().items():\n",
    "    print(k, decode([k]), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d64f3800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token = profile_models.sample_next(prefix)\n",
    "decode([next_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63a8d6",
   "metadata": {},
   "source": [
    "### Generate text for different emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9640283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 6477/6477 [00:00<00:00, 33042.20it/s]\n",
      "100%|████████████████████████████████████████████████████| 7490/7490 [00:00<00:00, 9422.75it/s]\n",
      "100%|███████████████████████████████████████████████████| 7637/7637 [00:00<00:00, 31848.55it/s]\n"
     ]
    }
   ],
   "source": [
    "models = dict([(profile, NGramModel(n=3)) for profile in corpora.keys()])\n",
    "for profile, model in models.items():\n",
    "    model.count_ngrams([[x for x in y if x != 0] for y in corpora[profile]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d1a9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(profile, start_word):\n",
    "    start, eos = 101, 102\n",
    "    start_prefix = tokenizer(start_word)['input_ids'][1]\n",
    "    prefix = [start, start_prefix]\n",
    "    for i in range(100):\n",
    "        next_token = models[profile].sample_next(prefix)\n",
    "        if next_token == eos:\n",
    "            break\n",
    "        else:\n",
    "            prefix.append(next_token)\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b90f9ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile A  :  nostalgic, sentimental, caring\n",
      "[CLS] I got the flu yesterday. I saw a lost kitten out of my old NES \n",
      "\n",
      "Profile B  :  angry, disappointed, furious\n",
      "[CLS] I can't know but I was camping last weekend and there wasn't cause a scene... but I am not happy. \n",
      "\n",
      "Profile C  :  grateful, content, excited\n",
      "[CLS] I am so proud of you! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for profile in corpora.keys():\n",
    "    text = generate(profile, start_word='I')\n",
    "    print(profile, ' : ', \", \".join(emotions[profile]))\n",
    "    print(decode(text), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274d81e",
   "metadata": {},
   "source": [
    "### Compute probabilities for classification purposes\n",
    "This test is made on the training set. Try to run this on the test set to verify how generalizing terminology is an issue for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ca7de",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = tokenizer('i wish i was looking through old pictures')['input_ids']\n",
    "model = models['Profile A']\n",
    "p = float('-inf')\n",
    "for chunk in ngrams(sentence, n=3, pad_left=True, left_pad_symbol=102):\n",
    "    prefix = chunk[-3:-1]\n",
    "    count = model.ngrams[prefix][chunk[-1]]\n",
    "    if count > 0:\n",
    "        p = np.log(count) - np.log(sum(model.ngrams[prefix].values()))\n",
    "        p += p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(profile, sentence_text):\n",
    "    sentence = tokenizer(sentence_text)['input_ids']\n",
    "    model = models[profile]\n",
    "    return model.eval_prob(sentence)\n",
    "\n",
    "def predict_tokens(profile, sentence):\n",
    "    model = models[profile]\n",
    "    return model.eval_prob(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bf67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('Profile A', 'i wish i was looking through old pictures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e758628",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbdff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = [], []\n",
    "profiles = list(corpora.keys())\n",
    "run = list(corpora.items())\n",
    "for profile, corpus in tqdm(run):\n",
    "    for sentence in corpus:\n",
    "        s = [x for x in sentence if x != 0]\n",
    "        predictions = [predict_tokens(p, s) for p in profiles]\n",
    "        y_pred.append(profiles[np.argmax(predictions)])\n",
    "        y_true.append(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7baf5",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccba724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3727e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, labels=profiles)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "disp.plot(ax=ax, cmap='Greens')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46684b23",
   "metadata": {},
   "source": [
    "## Perplexity\n",
    "Perlexity is the inverse of corpus probability.\n",
    "\n",
    "$$ Perplexity = e^{H(p)} = e^{\\sum_x{p(x) \\ln p(x)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa34eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d604a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(model, dataset, max_iterations=1000):\n",
    "    entropy = 0\n",
    "    num_words, num_iter = 0, 0\n",
    "    for i in range(max_iterations):\n",
    "        for sentence in islice(dataset, max_iterations):\n",
    "            sentence = [x for x in sentence if x != 0]\n",
    "            prefix = [sentence[1]]\n",
    "            for token in sentence[2:]:\n",
    "                try:            \n",
    "                    log_probs = model.compute_log_prob(prefix) \n",
    "                    entropy += log_probs[token]                 \n",
    "                except KeyError:\n",
    "                    entropy -= 100\n",
    "                prefix.append(token)\n",
    "                num_words += 1\n",
    "    mean_entropy = entropy / num_words\n",
    "    return np.exp(mean_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eded160",
   "metadata": {},
   "outputs": [],
   "source": [
    "for profile in profiles:\n",
    "    print(profile, ' : ', compute_perplexity(models[profile], corpora[profile], max_iterations=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3af4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crike",
   "language": "python",
   "name": "crike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
