{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive demonstration of a Markov Language Model \n",
    "\n",
    "We build a model that will compute\n",
    "$$\n",
    "P(w_1, \\dots, w_n) = \\prod\\limits_{i=1}^{n} P(w_i \\mid w_{i-m}, \\dots w_{i-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "0.3125\n",
      "0.0625\n"
     ]
    }
   ],
   "source": [
    "idx = {\n",
    "    'i': {'am': 100, 'have': 50, 'will': 10},\n",
    "    'am': {'happy': 2, 'sad': 5},\n",
    "\n",
    "}\n",
    "# P(am | I)\n",
    "print(idx['i']['am'] / sum(idx['i'].values()))\n",
    "print(idx['i']['have'] / sum(idx['i'].values()))\n",
    "print(idx['i']['will'] / sum(idx['i'].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = '/Users/flint/Data/sklearn/'\n",
    "subset = 'all'\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "data = fetch_20newsgroups(data_home=download_dir, subset=subset, remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' re ...\n",
      "--------\n",
      "10 rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "print(data.data[0][:250], '...')\n",
    "print('--------')\n",
    "print(data.target[0], data.target_names[data.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../nlp/')\n",
    "from nlp.markovlm import NaiveMarkovLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = NaiveMarkovLM(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.train(data.data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>actually</th>\n",
       "      <th>however</th>\n",
       "      <th>man</th>\n",
       "      <th>jagr</th>\n",
       "      <th>he</th>\n",
       "      <th>bowman</th>\n",
       "      <th>pens</th>\n",
       "      <th>!</th>\n",
       "      <th>my</th>\n",
       "      <th>...</th>\n",
       "      <th>made</th>\n",
       "      <th>3-4</th>\n",
       "      <th>flaming</th>\n",
       "      <th>wings</th>\n",
       "      <th>pizza</th>\n",
       "      <th>hut</th>\n",
       "      <th>commercial</th>\n",
       "      <th>tlu/a</th>\n",
       "      <th>gic</th>\n",
       "      <th>bait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">#S</th>\n",
       "      <th>#S</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>am</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <th>sure</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <th>some</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             i  actually  however  man  jagr   he  bowman  pens    !   my  \\\n",
       "#S   #S    9.0       1.0      1.0  1.0   1.0  1.0     1.0   1.0  1.0  2.0   \n",
       "     i     1.0       0.0      0.0  0.0   0.0  0.0     0.0   0.0  0.0  0.0   \n",
       "i    am    0.0       0.0      0.0  0.0   0.0  0.0     0.0   0.0  0.0  0.0   \n",
       "am   sure  0.0       0.0      0.0  0.0   0.0  0.0     0.0   0.0  0.0  0.0   \n",
       "sure some  0.0       0.0      0.0  0.0   0.0  0.0     0.0   0.0  0.0  0.0   \n",
       "\n",
       "           ...  made  3-4  flaming  wings  pizza  hut  commercial  tlu/a  gic  \\\n",
       "#S   #S    ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "     i     ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "i    am    ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "am   sure  ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "sure some  ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "\n",
       "           bait  \n",
       "#S   #S     0.0  \n",
       "     i      0.0  \n",
       "i    am     0.0  \n",
       "am   sure   0.0  \n",
       "sure some   0.0  \n",
       "\n",
       "[5 rows x 516 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.index.T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.791759469228055\n",
      "-1.252762968495368\n"
     ]
    }
   ],
   "source": [
    "seq = ('i', 'am', 'alfio')\n",
    "print(lm.P(*seq, log=True))\n",
    "seq = ('i', 'am', 'sure')\n",
    "print(lm.P(*seq, log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sure some bashers of Pens fans are pretty confused about the lackof any kind of posts about the recent Pens massacre of the Devils.\n",
      "-4.882801922586371\n"
     ]
    }
   ],
   "source": [
    "text = sent_tokenize(data.data[0])[0].replace('\\n', '')\n",
    "print(text)\n",
    "print(lm.joint_log_probability(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#S #S that was new .... #E\n"
     ]
    }
   ],
   "source": [
    "prefix = ('#S', '#S')\n",
    "text = list(lm.generate(prefix=prefix, max_len=20))\n",
    "print(\" \".join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "1. we train a general model over the whole corpus\n",
    "2. then, we clone the model into a specific model for each class \n",
    "3. we fine-tune the class-specific model for its class\n",
    "4. given a text, we compute the text probability for each class-model in order to select the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lm = NaiveMarkovLM(n=3)\n",
    "global_lm.train(documents=data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#S', '#S', 'the', 'azeri', 'town', 'on', 'a', 'level', 'consistent', 'with', 'that', '--', 'again', ',', 'you', 'can', 'obtain', 'the', 'above', 'represents', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(list(global_lm.generate(max_len=20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cloning and fine tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e5593d849f402987a21e3d6d29b411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_models = {}\n",
    "# Test with three classes only to speed up the process\n",
    "run = list(enumerate(data.target_names[:3]))\n",
    "for i, label in tqdm(run):\n",
    "    class_docs = [data.data[j] for j, k in enumerate(data.target) if k==i]\n",
    "    class_models[label] = global_lm.clone()\n",
    "    # fine turning\n",
    "    class_models[label].train(class_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc'])\n"
     ]
    }
   ],
   "source": [
    "print(class_models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class:  alt.atheism\n",
      "Prediction\n",
      "alt.atheism -121.81594594156735\n",
      "comp.graphics -122.4464521136665\n",
      "comp.os.ms-windows.misc -122.7542930595089\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -928.400391920057\n",
      "comp.graphics -935.5237164981246\n",
      "comp.os.ms-windows.misc -946.5383220033161\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -188.29301369058854\n",
      "comp.graphics -189.01899862453735\n",
      "comp.os.ms-windows.misc -192.11391284565815\n",
      "===========\n",
      "Correct class:  alt.atheism\n",
      "Prediction\n",
      "alt.atheism -2314.665188087034\n",
      "comp.graphics -2328.138985275299\n",
      "comp.os.ms-windows.misc -2346.8211299736836\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -434.15892132454286\n",
      "comp.graphics -435.72816410439407\n",
      "comp.os.ms-windows.misc -441.47625707730936\n",
      "===========\n",
      "Correct class:  comp.os.ms-windows.misc\n",
      "Prediction\n",
      "alt.atheism -664.4213946267886\n",
      "comp.graphics -667.7872258557901\n",
      "comp.os.ms-windows.misc -674.5441184644216\n",
      "===========\n",
      "Correct class:  comp.os.ms-windows.misc\n",
      "Prediction\n",
      "alt.atheism -330.9984957632746\n",
      "comp.graphics -331.5795050909201\n",
      "comp.os.ms-windows.misc -336.4851718359977\n",
      "===========\n",
      "Correct class:  alt.atheism\n",
      "Prediction\n",
      "alt.atheism -2155.8034799850266\n",
      "comp.graphics -2168.5312490145675\n",
      "comp.os.ms-windows.misc -2190.0090032546186\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -418.02975682934925\n",
      "comp.graphics -421.23939795349554\n",
      "comp.os.ms-windows.misc -420.74787774708454\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -5410.609310778752\n",
      "comp.graphics -5426.423960514891\n",
      "comp.os.ms-windows.misc -5464.879736895899\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -311.63904152105135\n",
      "comp.graphics -310.5846483225528\n",
      "comp.os.ms-windows.misc -314.5325327476677\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, doc in enumerate(data.data):\n",
    "    label = data.target_names[data.target[i]]\n",
    "    if label in class_models.keys():\n",
    "        print(\"Correct class: \", label)\n",
    "        print(\"Prediction\")\n",
    "        for pred, clm in class_models.items():\n",
    "            log_p = clm.joint_log_probability(doc)\n",
    "            print(pred, log_p)\n",
    "        count += 1\n",
    "        print(\"===========\")\n",
    "    if count > 10:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation\n",
    "1. we fine tune class-specific models as for classification\n",
    "2. we generate texts to see if they are consistent with the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "\t i am going , because as soon as possible if it was aggressively recruiting out of this british brigade was followed\n",
      "\t i am using exactly the point of fire ( or gaps ) between ingestion and its cause is kept separate from\n",
      "\t i am going to get parts . #E\n",
      "\t i am almost all of the 15 february 1989 remnant merits careful study of the ` auto ' tranny in f1\n",
      "comp.graphics\n",
      "\t i am a novice to the clipper header/signature . #E\n",
      "\t i am pretty sure theres an easy 4000 miles since new serialized , and it took almost two years behind the\n",
      "\t i am hitting the caps-lock and spreading . #E\n",
      "\t i am a few more sources relied upon the studies on this list answers many frequently asked questions on 77 occasions\n",
      "comp.os.ms-windows.misc\n",
      "\t i am interested to find some people consider the following : `` numerical recipes in c becaues of memory free ,\n",
      "\t i am looking for specific cancer patient populations , as though the 805 can address to 'moody monthly ' ? 2p\n",
      "\t i am not so with admirable verbal skill . #E\n",
      "\t i am looking for one , i have a pb100 that you 've got `` quadra '' comparable to adobe photo\n"
     ]
    }
   ],
   "source": [
    "prefix = ('i', 'am')\n",
    "for label, clm in class_models.items():\n",
    "    print(label)\n",
    "    for i in range(4):\n",
    "        print('\\t', \" \".join(list(clm.generate(prefix=prefix, max_len=20))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
