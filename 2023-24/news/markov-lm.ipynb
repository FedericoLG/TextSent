{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive demonstration of a Markov Language Model \n",
    "\n",
    "We build a model that will compute\n",
    "$$\n",
    "P(w_1, \\dots, w_n) = \\prod\\limits_{i=1}^{n} P(w_i \\mid w_{i-m}, \\dots w_{i-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = '/Users/flint/Data/sklearn/'\n",
    "subset = 'all'\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "data = fetch_20newsgroups(data_home=download_dir, subset=subset, remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' re ...\n",
      "--------\n",
      "10 rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "print(data.data[0][:250], '...')\n",
    "print('--------')\n",
    "print(data.target[0], data.target_names[data.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../nlp/')\n",
    "from nlp.markovlm import NaiveMarkovLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = NaiveMarkovLM(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.train(data.data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>actually</th>\n",
       "      <th>however</th>\n",
       "      <th>man</th>\n",
       "      <th>jagr</th>\n",
       "      <th>he</th>\n",
       "      <th>bowman</th>\n",
       "      <th>pens</th>\n",
       "      <th>!</th>\n",
       "      <th>my</th>\n",
       "      <th>...</th>\n",
       "      <th>made</th>\n",
       "      <th>3-4</th>\n",
       "      <th>flaming</th>\n",
       "      <th>wings</th>\n",
       "      <th>pizza</th>\n",
       "      <th>hut</th>\n",
       "      <th>commercial</th>\n",
       "      <th>tlu/a</th>\n",
       "      <th>gic</th>\n",
       "      <th>bait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">#S</th>\n",
       "      <th>#S</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>am</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <th>sure</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <th>some</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             i  actually  however  man  jagr   he  bowman  pens    !   my  \\\n",
       "#S   #S    9.0       1.0      1.0  1.0   1.0  1.0     1.0   1.0  1.0  2.0   \n",
       "     i     1.0       0.0      0.0  0.0   0.0  0.0     0.0   0.0  0.0  0.0   \n",
       "i    am    0.0       0.0      0.0  0.0   0.0  0.0     0.0   0.0  0.0  0.0   \n",
       "am   sure  0.0       0.0      0.0  0.0   0.0  0.0     0.0   0.0  0.0  0.0   \n",
       "sure some  0.0       0.0      0.0  0.0   0.0  0.0     0.0   0.0  0.0  0.0   \n",
       "\n",
       "           ...  made  3-4  flaming  wings  pizza  hut  commercial  tlu/a  gic  \\\n",
       "#S   #S    ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "     i     ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "i    am    ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "am   sure  ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "sure some  ...   0.0  0.0      0.0    0.0    0.0  0.0         0.0    0.0  0.0   \n",
       "\n",
       "           bait  \n",
       "#S   #S     0.0  \n",
       "     i      0.0  \n",
       "i    am     0.0  \n",
       "am   sure   0.0  \n",
       "sure some   0.0  \n",
       "\n",
       "[5 rows x 516 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.index.T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.791759469228055\n",
      "-1.252762968495368\n"
     ]
    }
   ],
   "source": [
    "seq = ('i', 'am', 'alfio')\n",
    "print(lm.P(*seq, log=True))\n",
    "seq = ('i', 'am', 'sure')\n",
    "print(lm.P(*seq, log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sure some bashers of Pens fans are pretty confused about the lackof any kind of posts about the recent Pens massacre of the Devils.\n",
      "-4.882801922586371\n"
     ]
    }
   ],
   "source": [
    "text = sent_tokenize(data.data[0])[0].replace('\\n', '')\n",
    "print(text)\n",
    "print(lm.joint_log_probability(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#S #S ! #E\n"
     ]
    }
   ],
   "source": [
    "prefix = ('#S', '#S')\n",
    "text = list(lm.generate(prefix=prefix, max_len=20))\n",
    "print(\" \".join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "1. we train a general model over the whole corpus\n",
    "2. then, we clone the model into a specific model for each class \n",
    "3. we fine-tune the class-specific model for its class\n",
    "4. given a text, we compute the text probability for each class-model in order to select the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lm = NaiveMarkovLM(n=3)\n",
    "global_lm.train(documents=data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#S', '#S', 'if', 'you', 'are', \"n't\", 'running', '.', '#E']\n"
     ]
    }
   ],
   "source": [
    "print(list(global_lm.generate(max_len=20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cloning and fine tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef31561319d14f218ba133693dba4687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_models = {}\n",
    "# Test with three classes only to speed up the process\n",
    "run = list(enumerate(data.target_names[:3]))\n",
    "for i, label in tqdm(run):\n",
    "    class_docs = [data.data[j] for j, k in enumerate(data.target) if k==i]\n",
    "    class_models[label] = global_lm.clone()\n",
    "    # fine turning\n",
    "    class_models[label].train(class_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc'])\n"
     ]
    }
   ],
   "source": [
    "print(class_models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class:  alt.atheism\n",
      "Prediction\n",
      "alt.atheism -137.80277922199454\n",
      "comp.graphics -138.07748550812423\n",
      "comp.os.ms-windows.misc -138.582829631957\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -1029.8680763235138\n",
      "comp.graphics -1034.1258635539702\n",
      "comp.os.ms-windows.misc -1045.4617026153967\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -201.77446261715642\n",
      "comp.graphics -202.0126661968555\n",
      "comp.os.ms-windows.misc -205.37547148798566\n",
      "===========\n",
      "Correct class:  alt.atheism\n",
      "Prediction\n",
      "alt.atheism -2402.879511230015\n",
      "comp.graphics -2413.6960941956645\n",
      "comp.os.ms-windows.misc -2433.8188997727807\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -434.15892132454286\n",
      "comp.graphics -435.72816410439407\n",
      "comp.os.ms-windows.misc -441.47625707730936\n",
      "===========\n",
      "Correct class:  comp.os.ms-windows.misc\n",
      "Prediction\n",
      "alt.atheism -664.4213946267886\n",
      "comp.graphics -667.7872258557901\n",
      "comp.os.ms-windows.misc -674.5441184644216\n",
      "===========\n",
      "Correct class:  comp.os.ms-windows.misc\n",
      "Prediction\n",
      "alt.atheism -330.9984957632746\n",
      "comp.graphics -331.5795050909201\n",
      "comp.os.ms-windows.misc -336.4851718359977\n",
      "===========\n",
      "Correct class:  alt.atheism\n",
      "Prediction\n",
      "alt.atheism -2155.8034799850266\n",
      "comp.graphics -2168.5312490145675\n",
      "comp.os.ms-windows.misc -2190.0090032546186\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -418.02975682934925\n",
      "comp.graphics -421.23939795349554\n",
      "comp.os.ms-windows.misc -420.74787774708454\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -5410.609310778752\n",
      "comp.graphics -5426.423960514891\n",
      "comp.os.ms-windows.misc -5464.879736895899\n",
      "===========\n",
      "Correct class:  comp.graphics\n",
      "Prediction\n",
      "alt.atheism -311.63904152105135\n",
      "comp.graphics -310.5846483225528\n",
      "comp.os.ms-windows.misc -314.5325327476677\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, doc in enumerate(data.data):\n",
    "    label = data.target_names[data.target[i]]\n",
    "    if label in class_models.keys():\n",
    "        print(\"Correct class: \", label)\n",
    "        print(\"Prediction\")\n",
    "        for pred, clm in class_models.items():\n",
    "            log_p = clm.joint_log_probability(doc)\n",
    "            print(pred, log_p)\n",
    "        count += 1\n",
    "        print(\"===========\")\n",
    "    if count > 10:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation\n",
    "1. we fine tune class-specific models as for classification\n",
    "2. we generate texts to see if they are consistent with the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "\t i am using it as optional ? #E\n",
      "\t i am sick and taking holiday snaps , but i prefer not to generalize about atheists and non-atheists on the case\n",
      "\t i am just now understanding that the la area that newer dsos are addressing . #E\n",
      "\t i am well aware that some jews and additional data . #E\n",
      "comp.graphics\n",
      "\t i am not mathew ( mantis ) but he 's setting himself up to 16 megahertz system speed ) ? ''\n",
      "\t i am running on the bids stop coming to have anything to be pulled because of the fundamental issues at hand\n",
      "\t i am describing , even a journalist who writes `` then man goes to a dog . #E\n",
      "\t i am from turkey . '' #E\n",
      "comp.os.ms-windows.misc\n",
      "\t i am to 12:00 pm and 1:00 pm today . #E\n",
      "\t i am not asking much . #E\n",
      "\t i am not ! #E\n",
      "\t i am looking pro a win for mr. vanderbyl ( no sex , right ? ) . #E\n"
     ]
    }
   ],
   "source": [
    "prefix = ('i', 'am')\n",
    "for label, clm in class_models.items():\n",
    "    print(label)\n",
    "    for i in range(4):\n",
    "        print('\\t', \" \".join(list(clm.generate(prefix=prefix, max_len=20))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
