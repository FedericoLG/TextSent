{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon-based sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../nlp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp.corpus import SpacyDbCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to use the MongoDb corpus class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = SpacyDbCorpus(db_name='nlp', collection='yelp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchers = [{'$or': [{'pos_': {'$in': ['NOUN', 'ADJ']}}, {'dep_': 'neg'}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': {'doc_id': 0, 'stars': 4}, 'tokens': [{'text': 'Red', 'lower': 'red', 'idx': 0, 'pos': 'ADJ', 'lemma': 'red', 'dep': 'amod', 'tag': 'JJ'}, {'text': 'white', 'lower': 'white', 'idx': 5, 'pos': 'ADJ', 'lemma': 'white', 'dep': 'conj', 'tag': 'JJ'}, {'text': 'salad', 'lower': 'salad', 'idx': 20, 'pos': 'NOUN', 'lemma': 'salad', 'dep': 'nsubj', 'tag': 'NN'}, {'text': 'super', 'lower': 'super', 'idx': 30, 'pos': 'ADJ', 'lemma': 'super', 'dep': 'advmod', 'tag': 'JJ'}, {'text': 'yum', 'lower': 'yum', 'idx': 36, 'pos': 'NOUN', 'lemma': 'yum', 'dep': 'attr', 'tag': 'NNS'}, {'text': 'great', 'lower': 'great', 'idx': 46, 'pos': 'ADJ', 'lemma': 'great', 'dep': 'amod', 'tag': 'JJ'}, {'text': 'addition', 'lower': 'addition', 'idx': 52, 'pos': 'NOUN', 'lemma': 'addition', 'dep': 'conj', 'tag': 'NN'}, {'text': 'menu', 'lower': 'menu', 'idx': 68, 'pos': 'NOUN', 'lemma': 'menu', 'dep': 'pobj', 'tag': 'NN'}, {'text': 'location', 'lower': 'location', 'idx': 79, 'pos': 'NOUN', 'lemma': 'location', 'dep': 'nsubj', 'tag': 'NN'}, {'text': 'clean', 'lower': 'clean', 'idx': 92, 'pos': 'ADJ', 'lemma': 'clean', 'dep': 'acomp', 'tag': 'JJ'}, {'text': 'great', 'lower': 'great', 'idx': 103, 'pos': 'ADJ', 'lemma': 'great', 'dep': 'amod', 'tag': 'JJ'}, {'text': 'service', 'lower': 'service', 'idx': 109, 'pos': 'NOUN', 'lemma': 'service', 'dep': 'pobj', 'tag': 'NN'}, {'text': 'food', 'lower': 'food', 'idx': 121, 'pos': 'NOUN', 'lemma': 'food', 'dep': 'conj', 'tag': 'NN'}, {'text': 'right', 'lower': 'right', 'idx': 145, 'pos': 'ADJ', 'lemma': 'right', 'dep': 'amod', 'tag': 'JJ'}, {'text': 'temps', 'lower': 'temps', 'idx': 151, 'pos': 'NOUN', 'lemma': 'temp', 'dep': 'pobj', 'tag': 'NNS'}, {'text': 'Kids', 'lower': 'kids', 'idx': 158, 'pos': 'NOUN', 'lemma': 'kid', 'dep': 'compound', 'tag': 'NNS'}, {'text': 'pizza', 'lower': 'pizza', 'idx': 163, 'pos': 'NOUN', 'lemma': 'pizza', 'dep': 'nsubj', 'tag': 'NN'}, {'text': 'hit', 'lower': 'hit', 'idx': 181, 'pos': 'NOUN', 'lemma': 'hit', 'dep': 'attr', 'tag': 'NN'}, {'text': 'lots', 'lower': 'lots', 'idx': 194, 'pos': 'NOUN', 'lemma': 'lot', 'dep': 'pobj', 'tag': 'NNS'}, {'text': 'great', 'lower': 'great', 'idx': 202, 'pos': 'ADJ', 'lemma': 'great', 'dep': 'amod', 'tag': 'JJ'}, {'text': 'side', 'lower': 'side', 'idx': 208, 'pos': 'NOUN', 'lemma': 'side', 'dep': 'compound', 'tag': 'NN'}, {'text': 'dish', 'lower': 'dish', 'idx': 213, 'pos': 'NOUN', 'lemma': 'dish', 'dep': 'compound', 'tag': 'NN'}, {'text': 'options', 'lower': 'options', 'idx': 218, 'pos': 'NOUN', 'lemma': 'option', 'dep': 'pobj', 'tag': 'NNS'}, {'text': 'kiddos', 'lower': 'kiddos', 'idx': 234, 'pos': 'NOUN', 'lemma': 'kiddo', 'dep': 'pobj', 'tag': 'NNS'}, {'text': 'side', 'lower': 'side', 'idx': 259, 'pos': 'NOUN', 'lemma': 'side', 'dep': 'pobj', 'tag': 'NN'}, {'text': 'town', 'lower': 'town', 'idx': 267, 'pos': 'NOUN', 'lemma': 'town', 'dep': 'pobj', 'tag': 'NN'}, {'text': 'spot', 'lower': 'spot', 'idx': 299, 'pos': 'NOUN', 'lemma': 'spot', 'dep': 'attr', 'tag': 'NN'}]}\n",
      "['red', 'white', 'salad', 'super', 'yum', 'great', 'addition', 'menu', 'location', 'clean', 'great', 'service', 'food', 'right', 'temp', 'kid', 'pizza', 'hit', 'lot', 'great', 'side', 'dish', 'option', 'kiddo', 'side', 'town', 'spot']\n"
     ]
    }
   ],
   "source": [
    "for document in corpus.get_corpus(filters=matchers, metadata=['stars'], limit=10):\n",
    "    print(document)\n",
    "    print([x['lemma'] for x in document['tokens']])\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER example [https://github.com/cjhutto/vaderSentiment](https://github.com/cjhutto/vaderSentiment)\n",
    "\n",
    "The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_text(doc):\n",
    "    return \" \".join(x['lower'] for x in doc['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [to_text(doc) for doc in corpus.get_corpus(limit=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red , white and bleu salad was super yum and a great addition to the menu !---------- {'neg': 0.0, 'neu': 0.644, 'pos': 0.356, 'compound': 0.8516}\n",
      "this location was clean with great service and food served at just the right temps !- {'neg': 0.0, 'neu': 0.664, 'pos': 0.336, 'compound': 0.7959}\n",
      "kids pizza is always a hit too with lots of great side dish options for the kiddos !- {'neg': 0.0, 'neu': 0.795, 'pos': 0.205, 'compound': 0.6588}\n",
      "when i 'm on this side of town , this will definitely be a spot i 'll hit up again !- {'neg': 0.0, 'neu': 0.87, 'pos': 0.13, 'compound': 0.4574}\n",
      "ate the momos during the momo crawl .. was the best of the lot so decided to eat at the restaurant and the mutton thali was equally good ! {'neg': 0.0, 'neu': 0.785, 'pos': 0.215, 'compound': 0.8122}\n",
      "!------------------------------------------------------------------------------------ {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "pizza here made my night ... good people and great pizza .--------------------------- {'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.7906}\n",
      "they can do anything you ask with a great attitude !--------------------------------- {'neg': 0.0, 'neu': 0.695, 'pos': 0.305, 'compound': 0.6588}\n",
      "great brisket sandwich as claimed .-------------------------------------------------- {'neg': 0.0, 'neu': 0.549, 'pos': 0.451, 'compound': 0.6249}\n",
      "weird that it 's a gas station\\/ hipster bbq lunch spot\\/ hallmark store carwash .--- {'neg': 0.108, 'neu': 0.892, 'pos': 0.0, 'compound': -0.1779}\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in sample:\n",
    "    for s in sent_tokenize(sentence):\n",
    "        vs = analyzer.polarity_scores(s)\n",
    "        print(\"{:-<85} {}\".format(s, str(vs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob example [https://textblob.readthedocs.io/en/dev/](https://textblob.readthedocs.io/en/dev/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red , white and bleu salad was super yum and a great addition to the menu !---------- P: 0.3333333333333333 S: 0.35416666666666663\n",
      "this location was clean with great service and food served at just the right temps !- P: 0.5079365079365079 S: 0.6619047619047619\n",
      "kids pizza is always a hit too with lots of great side dish options for the kiddos !- P: 1.0 S: 0.75\n",
      "when i 'm on this side of town , this will definitely be a spot i 'll hit up again !- P: 0.0 S: 0.5\n",
      "ate the momos during the momo crawl .. was the best of the lot so decided to eat at the restaurant and the mutton thali was equally good ! P: 0.9375 S: 0.45000000000000007\n",
      "!------------------------------------------------------------------------------------ P: 0.0 S: 0.0\n",
      "pizza here made my night ... good people and great pizza .--------------------------- P: 0.75 S: 0.675\n",
      "they can do anything you ask with a great attitude !--------------------------------- P: 1.0 S: 0.75\n",
      "great brisket sandwich as claimed .-------------------------------------------------- P: 0.8 S: 0.75\n",
      "weird that it 's a gas station\\/ hipster bbq lunch spot\\/ hallmark store carwash .--- P: -0.5 S: 1.0\n"
     ]
    }
   ],
   "source": [
    "for sentence in sample:\n",
    "    for s in sent_tokenize(sentence):\n",
    "        blob = TextBlob(s)\n",
    "        print(\"{:-<85} P: {} S: {}\".format(s, blob.sentiment.polarity, blob.sentiment.subjectivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentiWordnet [https://www.nltk.org/howto/sentiwordnet.html](https://www.nltk.org/howto/sentiwordnet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red\n",
      "\tred.n.01                   0.0     0.375     0.625\n",
      "\tred.n.02                   0.0       0.0       1.0\n",
      "\tbolshevik.n.01           0.125     0.125      0.75\n",
      "\tloss.n.06                  0.0       0.0       1.0\n",
      "\tred.s.01                   0.0       0.0       1.0\n",
      "\tcrimson.s.02              0.25     0.625     0.125\n",
      "\tcrimson.s.03               0.0      0.25      0.75\n",
      "ate\n",
      "\tate.n.01                   0.0       0.0       1.0\n",
      "\teat.v.01                   0.0       0.0       1.0\n",
      "\teat.v.02                   0.0       0.0       1.0\n",
      "\tfeed.v.06                  0.0       0.0       1.0\n",
      "\teat.v.04                  0.25       0.0      0.75\n",
      "\tconsume.v.05               0.0       0.0       1.0\n",
      "\tcorrode.v.01               0.0       0.0       1.0\n",
      "pizza\n",
      "\tpizza.n.01                 0.0       0.0       1.0\n",
      "great\n",
      "\tgreat.n.01                 0.0       0.0       1.0\n",
      "\tgreat.s.01                 0.0       0.0       1.0\n",
      "\tgreat.s.02                0.75       0.0      0.25\n",
      "\tgreat.s.03                0.25     0.125     0.625\n",
      "\tbang-up.s.01             0.875       0.0     0.125\n",
      "\tcapital.s.03               0.0       0.0       1.0\n",
      "\tbig.s.13                   0.0       0.0       1.0\n"
     ]
    }
   ],
   "source": [
    "for sentence in sample:\n",
    "    for s in sent_tokenize(sentence):\n",
    "        for word in s.split():\n",
    "            synsets = list(swn.senti_synsets(word))\n",
    "            print(word)\n",
    "            for syn in synsets:\n",
    "                print(\"\\t{:20}{:10}{:10}{:10}\".format(syn.synset.name(), syn.pos_score(), syn.neg_score(), syn.obj_score()))\n",
    "            break \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
