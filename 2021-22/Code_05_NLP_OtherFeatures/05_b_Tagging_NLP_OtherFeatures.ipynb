{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one, and preferably only one, obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than right now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea, let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "text = open('the-zen-of-python.txt','r').read()\n",
    "\n",
    "print(text)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text_tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 18), ('is', 10), ('better', 8), ('than', 8), (',', 6)]\n",
      "     .     is better   than      , \n",
      "    18     10      8      8      6 \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "fd = nltk.FreqDist(text_tokens)\n",
    "\n",
    "print(fd.most_common(5))\n",
    "\n",
    "print(fd.tabulate(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Beautiful', 'NNP'), ('is', 'VBZ'), ('better', 'JJR'), ('than', 'IN'), ('ugly', 'RB'), ('.', '.'), ('Explicit', 'NNP'), ('is', 'VBZ'), ('better', 'JJR'), ('than', 'IN'), ('implicit', 'NN'), ('.', '.'), ('Simple', 'NNP'), ('is', 'VBZ'), ('better', 'JJR'), ('than', 'IN'), ('complex', 'JJ'), ('.', '.'), ('Complex', 'NNP'), ('is', 'VBZ'), ('better', 'JJR'), ('than', 'IN'), ('complicated', 'VBN'), ('.', '.'), ('Flat', 'NNP'), ('is', 'VBZ'), ('better', 'JJR'), ('than', 'IN'), ('nested', 'VBN'), ('.', '.'), ('Sparse', 'NNP'), ('is', 'VBZ'), ('better', 'JJR'), ('than', 'IN'), ('dense', 'NN'), ('.', '.'), ('Readability', 'NN'), ('counts', 'NNS'), ('.', '.'), ('Special', 'JJ'), ('cases', 'NNS'), ('are', 'VBP'), (\"n't\", 'RB'), ('special', 'JJ'), ('enough', 'RB'), ('to', 'TO'), ('break', 'VB'), ('the', 'DT'), ('rules', 'NNS'), ('.', '.'), ('Although', 'IN'), ('practicality', 'NN'), ('beats', 'NNS'), ('purity', 'NN'), ('.', '.'), ('Errors', 'NNS'), ('should', 'MD'), ('never', 'RB'), ('pass', 'VB'), ('silently', 'RB'), ('.', '.'), ('Unless', 'NNP'), ('explicitly', 'RB'), ('silenced', 'VBD'), ('.', '.'), ('In', 'IN'), ('the', 'DT'), ('face', 'NN'), ('of', 'IN'), ('ambiguity', 'NN'), (',', ','), ('refuse', 'VB'), ('the', 'DT'), ('temptation', 'NN'), ('to', 'TO'), ('guess', 'VB'), ('.', '.'), ('There', 'EX'), ('should', 'MD'), ('be', 'VB'), ('one', 'CD'), (',', ','), ('and', 'CC'), ('preferably', 'RB'), ('only', 'RB'), ('one', 'CD'), (',', ','), ('obvious', 'JJ'), ('way', 'NN'), ('to', 'TO'), ('do', 'VB'), ('it', 'PRP'), ('.', '.'), ('Although', 'IN'), ('that', 'DT'), ('way', 'NN'), ('may', 'MD'), ('not', 'RB'), ('be', 'VB'), ('obvious', 'JJ'), ('at', 'IN'), ('first', 'JJ'), ('unless', 'IN'), ('you', 'PRP'), (\"'re\", 'VBP'), ('Dutch', 'JJ'), ('.', '.'), ('Now', 'RB'), ('is', 'VBZ'), ('better', 'RBR'), ('than', 'IN'), ('never', 'RB'), ('.', '.'), ('Although', 'IN'), ('never', 'RB'), ('is', 'VBZ'), ('often', 'RB'), ('better', 'JJR'), ('than', 'IN'), ('right', 'RB'), ('now', 'RB'), ('.', '.'), ('If', 'IN'), ('the', 'DT'), ('implementation', 'NN'), ('is', 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('explain', 'VB'), (',', ','), ('it', 'PRP'), (\"'s\", 'VBZ'), ('a', 'DT'), ('bad', 'JJ'), ('idea', 'NN'), ('.', '.'), ('If', 'IN'), ('the', 'DT'), ('implementation', 'NN'), ('is', 'VBZ'), ('easy', 'JJ'), ('to', 'TO'), ('explain', 'VB'), (',', ','), ('it', 'PRP'), ('may', 'MD'), ('be', 'VB'), ('a', 'DT'), ('good', 'JJ'), ('idea', 'NN'), ('.', '.'), ('Namespaces', 'NNS'), ('are', 'VBP'), ('one', 'CD'), ('honking', 'VBG'), ('great', 'JJ'), ('idea', 'NN'), (',', ','), ('let', 'VB'), (\"'s\", 'POS'), ('do', 'VB'), ('more', 'JJR'), ('of', 'IN'), ('those', 'DT'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "text_POS_tag = nltk.pos_tag(text_tokens, lang='eng')\n",
    "\n",
    "print(text_POS_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untagging a tagged sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beautiful', 'is', 'better', 'than', 'ugly', '.', 'Explicit', 'is', 'better', 'than', 'implicit', '.', 'Simple', 'is', 'better', 'than', 'complex', '.', 'Complex', 'is', 'better', 'than', 'complicated', '.', 'Flat', 'is', 'better', 'than', 'nested', '.', 'Sparse', 'is', 'better', 'than', 'dense', '.', 'Readability', 'counts', '.', 'Special', 'cases', 'are', \"n't\", 'special', 'enough', 'to', 'break', 'the', 'rules', '.', 'Although', 'practicality', 'beats', 'purity', '.', 'Errors', 'should', 'never', 'pass', 'silently', '.', 'Unless', 'explicitly', 'silenced', '.', 'In', 'the', 'face', 'of', 'ambiguity', ',', 'refuse', 'the', 'temptation', 'to', 'guess', '.', 'There', 'should', 'be', 'one', ',', 'and', 'preferably', 'only', 'one', ',', 'obvious', 'way', 'to', 'do', 'it', '.', 'Although', 'that', 'way', 'may', 'not', 'be', 'obvious', 'at', 'first', 'unless', 'you', \"'re\", 'Dutch', '.', 'Now', 'is', 'better', 'than', 'never', '.', 'Although', 'never', 'is', 'often', 'better', 'than', 'right', 'now', '.', 'If', 'the', 'implementation', 'is', 'hard', 'to', 'explain', ',', 'it', \"'s\", 'a', 'bad', 'idea', '.', 'If', 'the', 'implementation', 'is', 'easy', 'to', 'explain', ',', 'it', 'may', 'be', 'a', 'good', 'idea', '.', 'Namespaces', 'are', 'one', 'honking', 'great', 'idea', ',', 'let', \"'s\", 'do', 'more', 'of', 'those', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import untag\n",
    "\n",
    "print(untag(text_POS_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore our tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 19, 'IN': 18, 'RB': 15, 'NN': 15, 'JJ': 12, 'VB': 12, 'VBZ': 11, 'DT': 9, 'JJR': 8, 'NNP': 7, ...})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tags ordered by frequency\n",
    "\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in text_POS_tag)\n",
    "tag_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'TO': 5, 'RB': 2, ',': 2, 'MD': 2, 'POS': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's inspect some tagged text to see what parts of speech occur before a verb (base form)\n",
    "\n",
    "word_tag_pairs = nltk.bigrams(text_POS_tag)\n",
    "nltk.FreqDist([a[1] for (a, b) in word_tag_pairs if b[1] == 'VB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NNP': 6, 'TO': 5, 'RB': 5, 'IN': 2, 'NNS': 2, ',': 2, 'MD': 2, 'PRP': 2, 'NN': 2, 'CD': 1, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's inspect some tagged text to see what parts of speech occur before a verb (any type of)\n",
    "\n",
    "word_tag_pairs = nltk.bigrams(text_POS_tag)\n",
    "nltk.FreqDist([a[1] for (a, b) in word_tag_pairs if b[1].startswith('VB')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['break', 'pass', 'refuse', 'guess', 'be', 'do', 'explain', 'let'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words and tags are paired, so we can treat the tag as a condition and the word as an event, and initialize a conditional frequency distribution with a list of condition-event pairs and we can see likely words for a given tag\n",
    "cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in text_POS_tag)\n",
    "cfd['VB'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB [('be', 3), ('do', 2), ('explain', 2), ('break', 1), ('pass', 1)]\n",
      "VBD [('silenced', 1)]\n",
      "VBG [('honking', 1)]\n",
      "VBN [('complicated', 1), ('nested', 1)]\n",
      "VBP [('are', 2), (\"'re\", 1)]\n",
      "VBZ [('is', 10), (\"'s\", 1)]\n"
     ]
    }
   ],
   "source": [
    "# Let's find the most frequent verbs of each noun part-of-speech type.\n",
    "def findtags(tag_prefix, tagged_text):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
    "                                  if tag.startswith(tag_prefix))\n",
    "    return dict((tag, cfd[tag].most_common(5)) for tag in cfd.conditions())\n",
    "\n",
    "tagdict = findtags('VB', text_POS_tag)\n",
    "\n",
    "for tag in sorted(tagdict):\n",
    "    print(tag, tagdict[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJR  JJ RBR  RB \n",
      "  6   2   1   1 \n"
     ]
    }
   ],
   "source": [
    "# Suppose we're studying the verb 'is' and want to see how it is used in text\n",
    "fd = nltk.FreqDist([b[1] for (a, b) in nltk.bigrams(text_POS_tag) if a[0] == 'is'])\n",
    "\n",
    "fd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful is better\n",
      "Explicit is better\n",
      "Simple is better\n",
      "Complex is better\n",
      "Flat is better\n",
      "Sparse is better\n",
      "implementation is hard\n",
      "implementation is easy\n"
     ]
    }
   ],
   "source": [
    "# Let's find words involving particular sequences of tags and words\n",
    "def process(text_tags, first_='NN', middle_='is', second_='JJ'):\n",
    "    triGram_tag = nltk.trigrams(text_tags)\n",
    "    for ((w1,t1), (w2,t2), (w3,t3)) in triGram_tag:\n",
    "        if (t1.startswith(first_) and w2.lower() == middle_ and t3.startswith(second_)):\n",
    "            print(w1, w2, w3)\n",
    "\n",
    "process(text_POS_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s VBZ POS\n",
      "better JJR RBR\n",
      "complex JJ NNP\n",
      "unless NNP IN\n"
     ]
    }
   ],
   "source": [
    "# Let's look for words that are highly ambiguous as to their part of speech tag\n",
    "data = nltk.ConditionalFreqDist((word.lower(), tag) for (word, tag) in text_POS_tag)\n",
    "\n",
    "for word in sorted(data.conditions()):\n",
    "    if len(data[word]) >= 2:\n",
    "        tags = [tag for (tag, _) in data[word].most_common()]\n",
    "        print(word, ' '.join(tags))\n",
    "\n",
    "# These can help us clarify the distinctions between the tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default tagging: the simplest (useless?) way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Beautiful', 'NN'), ('is', 'NN'), ('better', 'NN'), ('than', 'NN'), ('ugly', 'NN'), ('.', 'NN'), ('Explicit', 'NN'), ('is', 'NN'), ('better', 'NN'), ('than', 'NN'), ('implicit', 'NN'), ('.', 'NN'), ('Simple', 'NN'), ('is', 'NN'), ('better', 'NN'), ('than', 'NN'), ('complex', 'NN'), ('.', 'NN'), ('Complex', 'NN'), ('is', 'NN'), ('better', 'NN'), ('than', 'NN'), ('complicated', 'NN'), ('.', 'NN'), ('Flat', 'NN'), ('is', 'NN'), ('better', 'NN'), ('than', 'NN'), ('nested', 'NN'), ('.', 'NN'), ('Sparse', 'NN'), ('is', 'NN'), ('better', 'NN'), ('than', 'NN'), ('dense', 'NN'), ('.', 'NN'), ('Readability', 'NN'), ('counts', 'NN'), ('.', 'NN'), ('Special', 'NN'), ('cases', 'NN'), ('are', 'NN'), (\"n't\", 'NN'), ('special', 'NN'), ('enough', 'NN'), ('to', 'NN'), ('break', 'NN'), ('the', 'NN'), ('rules', 'NN'), ('.', 'NN'), ('Although', 'NN'), ('practicality', 'NN'), ('beats', 'NN'), ('purity', 'NN'), ('.', 'NN'), ('Errors', 'NN'), ('should', 'NN'), ('never', 'NN'), ('pass', 'NN'), ('silently', 'NN'), ('.', 'NN'), ('Unless', 'NN'), ('explicitly', 'NN'), ('silenced', 'NN'), ('.', 'NN'), ('In', 'NN'), ('the', 'NN'), ('face', 'NN'), ('of', 'NN'), ('ambiguity', 'NN'), (',', 'NN'), ('refuse', 'NN'), ('the', 'NN'), ('temptation', 'NN'), ('to', 'NN'), ('guess', 'NN'), ('.', 'NN'), ('There', 'NN'), ('should', 'NN'), ('be', 'NN'), ('one', 'NN'), (',', 'NN'), ('and', 'NN'), ('preferably', 'NN'), ('only', 'NN'), ('one', 'NN'), (',', 'NN'), ('obvious', 'NN'), ('way', 'NN'), ('to', 'NN'), ('do', 'NN'), ('it', 'NN'), ('.', 'NN'), ('Although', 'NN'), ('that', 'NN'), ('way', 'NN'), ('may', 'NN'), ('not', 'NN'), ('be', 'NN'), ('obvious', 'NN'), ('at', 'NN'), ('first', 'NN'), ('unless', 'NN'), ('you', 'NN'), (\"'re\", 'NN'), ('Dutch', 'NN'), ('.', 'NN'), ('Now', 'NN'), ('is', 'NN'), ('better', 'NN'), ('than', 'NN'), ('never', 'NN'), ('.', 'NN'), ('Although', 'NN'), ('never', 'NN'), ('is', 'NN'), ('often', 'NN'), ('better', 'NN'), ('than', 'NN'), ('right', 'NN'), ('now', 'NN'), ('.', 'NN'), ('If', 'NN'), ('the', 'NN'), ('implementation', 'NN'), ('is', 'NN'), ('hard', 'NN'), ('to', 'NN'), ('explain', 'NN'), (',', 'NN'), ('it', 'NN'), (\"'s\", 'NN'), ('a', 'NN'), ('bad', 'NN'), ('idea', 'NN'), ('.', 'NN'), ('If', 'NN'), ('the', 'NN'), ('implementation', 'NN'), ('is', 'NN'), ('easy', 'NN'), ('to', 'NN'), ('explain', 'NN'), (',', 'NN'), ('it', 'NN'), ('may', 'NN'), ('be', 'NN'), ('a', 'NN'), ('good', 'NN'), ('idea', 'NN'), ('.', 'NN'), ('Namespaces', 'NN'), ('are', 'NN'), ('one', 'NN'), ('honking', 'NN'), ('great', 'NN'), ('idea', 'NN'), (',', 'NN'), ('let', 'NN'), (\"'s\", 'NN'), ('do', 'NN'), ('more', 'NN'), ('of', 'NN'), ('those', 'NN'), ('!', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "\n",
    "tagger = DefaultTagger('NN')\n",
    "\n",
    "print(tagger.tag(text_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Regular Expression Tagger: build your own tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Beautiful', 'NN'), ('is', 'NNS'), ('better', 'NN'), ('than', 'NN'), ('ugly', 'NN'), ('.', 'NN'), ('Explicit', 'NN'), ('is', 'NNS'), ('better', 'NN'), ('than', 'NN'), ('implicit', 'NN'), ('.', 'NN'), ('Simple', 'NN'), ('is', 'NNS'), ('better', 'NN'), ('than', 'NN'), ('complex', 'NN'), ('.', 'NN'), ('Complex', 'NN'), ('is', 'NNS'), ('better', 'NN'), ('than', 'NN'), ('complicated', 'VBD'), ('.', 'NN'), ('Flat', 'NN'), ('is', 'NNS'), ('better', 'NN'), ('than', 'NN'), ('nested', 'VBD'), ('.', 'NN'), ('Sparse', 'NN'), ('is', 'NNS'), ('better', 'NN'), ('than', 'NN'), ('dense', 'NN'), ('.', 'NN'), ('Readability', 'NN'), ('counts', 'NNS'), ('.', 'NN'), ('Special', 'NN'), ('cases', 'VBZ'), ('are', 'NN'), (\"n't\", 'NN'), ('special', 'NN'), ('enough', 'NN'), ('to', 'NN'), ('break', 'NN'), ('the', 'NN'), ('rules', 'VBZ'), ('.', 'NN'), ('Although', 'NN'), ('practicality', 'NN'), ('beats', 'NNS'), ('purity', 'NN'), ('.', 'NN'), ('Errors', 'NNS'), ('should', 'MD'), ('never', 'NN'), ('pass', 'NNS'), ('silently', 'NN'), ('.', 'NN'), ('Unless', 'NNS'), ('explicitly', 'NN'), ('silenced', 'VBD'), ('.', 'NN'), ('In', 'NN'), ('the', 'NN'), ('face', 'NN'), ('of', 'NN'), ('ambiguity', 'NN'), (',', 'NN'), ('refuse', 'NN'), ('the', 'NN'), ('temptation', 'NN'), ('to', 'NN'), ('guess', 'NNS'), ('.', 'NN'), ('There', 'NN'), ('should', 'MD'), ('be', 'NN'), ('one', 'NN'), (',', 'NN'), ('and', 'NN'), ('preferably', 'NN'), ('only', 'NN'), ('one', 'NN'), (',', 'NN'), ('obvious', 'NNS'), ('way', 'NN'), ('to', 'NN'), ('do', 'NN'), ('it', 'NN'), ('.', 'NN'), ('Although', 'NN'), ('that', 'NN'), ('way', 'NN'), ('may', 'NN'), ('not', 'NN'), ('be', 'NN'), ('obvious', 'NNS'), ('at', 'NN'), ('first', 'NN'), ('unless', 'NNS'), ('you', 'NN'), (\"'re\", 'NN'), ('Dutch', 'NN'), ('.', 'NN'), ('Now', 'NN'), ('is', 'NNS'), ('better', 'NN'), ('than', 'NN'), ('never', 'NN'), ('.', 'NN'), ('Although', 'NN'), ('never', 'NN'), ('is', 'NNS'), ('often', 'NN'), ('better', 'NN'), ('than', 'NN'), ('right', 'NN'), ('now', 'NN'), ('.', 'NN'), ('If', 'NN'), ('the', 'NN'), ('implementation', 'NN'), ('is', 'NNS'), ('hard', 'NN'), ('to', 'NN'), ('explain', 'NN'), (',', 'NN'), ('it', 'NN'), (\"'s\", 'NN$'), ('a', 'NN'), ('bad', 'NN'), ('idea', 'NN'), ('.', 'NN'), ('If', 'NN'), ('the', 'NN'), ('implementation', 'NN'), ('is', 'NNS'), ('easy', 'NN'), ('to', 'NN'), ('explain', 'NN'), (',', 'NN'), ('it', 'NN'), ('may', 'NN'), ('be', 'NN'), ('a', 'NN'), ('good', 'NN'), ('idea', 'NN'), ('.', 'NN'), ('Namespaces', 'VBZ'), ('are', 'NN'), ('one', 'NN'), ('honking', 'VBG'), ('great', 'NN'), ('idea', 'NN'), (',', 'NN'), ('let', 'NN'), (\"'s\", 'NN$'), ('do', 'NN'), ('more', 'NN'), ('of', 'NN'), ('those', 'NN'), ('!', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "patterns = [\n",
    "(r'.*ing$', 'VBG'),                # gerunds\n",
    "(r'.*ed$', 'VBD'),                 # simple past\n",
    "(r'.*es$', 'VBZ'),                 # 3rd singular present\n",
    "(r'.*ould$', 'MD'),                # modals\n",
    "(r'.*\\'s$', 'NN$'),                # possessive nouns\n",
    "(r'.*s$', 'NNS'),                  # plural nouns\n",
    "(r'^-?[0-9]+(\\.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "(r'.*', 'NN')                      # nouns (default)\n",
    "]\n",
    "\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "print(regexp_tagger.tag(text_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lookup Tagger: for each word, identify its most frequent tag, and use this information to tag words in next text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45578495136941344\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_words = brown.tagged_words(categories='news')\n",
    "test_sents = brown.tagged_sents(categories='news')\n",
    "\n",
    "fd_brown = nltk.FreqDist(brown.words(categories='news'))\n",
    "cfd_brown = nltk.ConditionalFreqDist(brown_tagged_words)\n",
    "most_freq_words_brown = fd_brown.most_common(100)\n",
    "\n",
    "likely_tags = dict((word, cfd_brown[word].max()) for (word, _) in most_freq_words_brown)\n",
    "\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
    "\n",
    "print(baseline_tagger.accuracy(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.459056825188456\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "#nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "treebank_tagged_words = treebank.tagged_words()\n",
    "\n",
    "fd_treebank = nltk.FreqDist(treebank.words())\n",
    "cfd_treebank = nltk.ConditionalFreqDist(treebank_tagged_words)\n",
    "most_freq_words_treebank = fd_treebank.most_common(100) #1000\n",
    "\n",
    "other_tags = dict((word, cfd_treebank[word].max()) for (word, _) in most_freq_words_treebank)\n",
    "\n",
    "other_tagger = nltk.UnigramTagger(model=other_tags)\n",
    "\n",
    "enanched_tagger = nltk.UnigramTagger(model=likely_tags, backoff=other_tagger)\n",
    "\n",
    "print(enanched_tagger.accuracy(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({None: 87, '.': 18, 'IN': 12, 'BEZ': 10, 'AT': 7, ',': 6, 'TO': 5, 'BE': 3, 'CD': 3, 'PPS': 3, ...})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But we didn't customize it...\n",
    "\n",
    "nltk.FreqDist(tag for (word, tag) in enanched_tagger.tag(text_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Beautiful', None), ('is', 'BEZ'), ('better', None), ('than', 'IN'), ('ugly', None), ('.', '.'), ('Explicit', None), ('is', 'BEZ'), ('better', None), ('than', 'IN'), ('implicit', None), ('.', '.'), ('Simple', None), ('is', 'BEZ'), ('better', None), ('than', 'IN'), ('complex', None), ('.', '.'), ('Complex', None), ('is', 'BEZ'), ('better', None), ('than', 'IN'), ('complicated', None), ('.', '.'), ('Flat', None), ('is', 'BEZ'), ('better', None), ('than', 'IN'), ('nested', None), ('.', '.'), ('Sparse', None), ('is', 'BEZ'), ('better', None), ('than', 'IN'), ('dense', None), ('.', '.'), ('Readability', None), ('counts', None), ('.', '.'), ('Special', None), ('cases', None), ('are', 'BER'), (\"n't\", 'RB'), ('special', None), ('enough', None), ('to', 'TO'), ('break', None), ('the', 'AT'), ('rules', None), ('.', '.'), ('Although', None), ('practicality', None), ('beats', None), ('purity', None), ('.', '.'), ('Errors', None), ('should', None), ('never', None), ('pass', None), ('silently', None), ('.', '.'), ('Unless', None), ('explicitly', None), ('silenced', None), ('.', '.'), ('In', 'IN'), ('the', 'AT'), ('face', None), ('of', 'IN'), ('ambiguity', None), (',', ','), ('refuse', None), ('the', 'AT'), ('temptation', None), ('to', 'TO'), ('guess', None), ('.', '.'), ('There', None), ('should', None), ('be', 'BE'), ('one', 'CD'), (',', ','), ('and', 'CC'), ('preferably', None), ('only', 'AP'), ('one', 'CD'), (',', ','), ('obvious', None), ('way', None), ('to', 'TO'), ('do', None), ('it', 'PPS'), ('.', '.'), ('Although', None), ('that', 'CS'), ('way', None), ('may', None), ('not', '*'), ('be', 'BE'), ('obvious', None), ('at', 'IN'), ('first', 'OD'), ('unless', None), ('you', None), (\"'re\", None), ('Dutch', None), ('.', '.'), ('Now', None), ('is', 'BEZ'), ('better', None), ('than', 'IN'), ('never', None), ('.', '.'), ('Although', None), ('never', None), ('is', 'BEZ'), ('often', None), ('better', None), ('than', 'IN'), ('right', None), ('now', None), ('.', '.'), ('If', None), ('the', 'AT'), ('implementation', None), ('is', 'BEZ'), ('hard', None), ('to', 'TO'), ('explain', None), (',', ','), ('it', 'PPS'), (\"'s\", 'POS'), ('a', 'AT'), ('bad', None), ('idea', None), ('.', '.'), ('If', None), ('the', 'AT'), ('implementation', None), ('is', 'BEZ'), ('easy', None), ('to', 'TO'), ('explain', None), (',', ','), ('it', 'PPS'), ('may', None), ('be', 'BE'), ('a', 'AT'), ('good', None), ('idea', None), ('.', '.'), ('Namespaces', None), ('are', 'BER'), ('one', 'CD'), ('honking', None), ('great', None), ('idea', None), (',', ','), ('let', None), (\"'s\", 'POS'), ('do', None), ('more', 'AP'), ('of', 'IN'), ('those', None), ('!', None)]\n"
     ]
    }
   ],
   "source": [
    "print(enanched_tagger.tag(text_tokens))\n",
    "\n",
    "#lot's of 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    POS     TAG     Dep     POS explained       TAG explained\n",
      "Your     PRON     PRP$     poss     pronoun              pronoun, possessive\n",
      "time     NOUN     NN       nsubjpass noun                 noun, singular or mass\n",
      "is       AUX      VBZ      auxpass  auxiliary            verb, 3rd person singular present\n",
      "limited  VERB     VBN      ccomp    verb                 verb, past participle\n",
      ",        PUNCT    ,        punct    punctuation          punctuation mark, comma\n",
      "so       ADV      RB       advmod   adverb               adverb\n",
      "do       AUX      VBP      aux      auxiliary            verb, non-3rd person singular present\n",
      "n't      PART     RB       neg      particle             adverb\n",
      "waste    VERB     VB       ROOT     verb                 verb, base form\n",
      "it       PRON     PRP      dobj     pronoun              pronoun, personal\n",
      "living   VERB     VBG      advcl    verb                 verb, gerund or present participle\n",
      "someone  PRON     NN       nmod     pronoun              noun, singular or mass\n",
      "else     ADV      RB       advmod   adverb               adverb\n",
      "'s       PART     POS      case     particle             possessive ending\n",
      "life     NOUN     NN       dobj     noun                 noun, singular or mass\n",
      ".        PUNCT    .        punct    punctuation          punctuation mark, sentence closer\n",
      "Do       AUX      VB       aux      auxiliary            verb, base form\n",
      "n't      PART     RB       neg      particle             adverb\n",
      "be       AUX      VB       auxpass  auxiliary            verb, base form\n",
      "trapped  VERB     VBN      ROOT     verb                 verb, past participle\n",
      "by       ADP      IN       agent    adposition           conjunction, subordinating or preposition\n",
      "dogma    NOUN     NN       pobj     noun                 noun, singular or mass\n",
      ",        PUNCT    ,        punct    punctuation          punctuation mark, comma\n",
      "which    PRON     WDT      nsubj    pronoun              wh-determiner\n",
      "is       AUX      VBZ      aux      auxiliary            verb, 3rd person singular present\n",
      "living   VERB     VBG      relcl    verb                 verb, gerund or present participle\n",
      "with     ADP      IN       prep     adposition           conjunction, subordinating or preposition\n",
      "the      DET      DT       det      determiner           determiner\n",
      "results  NOUN     NNS      pobj     noun                 noun, plural\n",
      "of       ADP      IN       prep     adposition           conjunction, subordinating or preposition\n",
      "other    ADJ      JJ       amod     adjective            adjective (English), other noun-modifier (Chinese)\n",
      "people   NOUN     NNS      poss     noun                 noun, plural\n",
      "'s       PART     POS      case     particle             possessive ending\n",
      "thinking NOUN     NN       pobj     noun                 noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "#   Part-of-speech tagging\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Your time is limited, so don't waste it living someone else's life. Don't be trapped by dogma, which is living with the results of other people's thinking\")\n",
    "\n",
    "print(f\"{'text':{8}}{'POS':{8}}{'TAG':{8}}{'Dep':{8}}{'POS explained':{20}}{'TAG explained'}\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:{8}} {token.pos_:{8}} {token.tag_:{8}} {token.dep_:{8}} {spacy.explain(token.pos_):{20}} {spacy.explain(token.tag_)}')\n",
    "\n",
    "#  Token attributes :   https://spacy.io/api/token#attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your\n",
      "{'Person': '2', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "----\n",
      "time\n",
      "{'Number': 'Sing'}\n",
      "----\n",
      "is\n",
      "{'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "----\n",
      "limited\n",
      "{'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "----\n",
      ",\n",
      "{'PunctType': 'Comm'}\n",
      "----\n",
      "so\n",
      "{}\n",
      "----\n",
      "do\n",
      "{'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "----\n",
      "n't\n",
      "{'Polarity': 'Neg'}\n",
      "----\n",
      "waste\n",
      "{'VerbForm': 'Inf'}\n",
      "----\n",
      "it\n",
      "{'Case': 'Acc', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "----\n",
      "living\n",
      "{'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "----\n",
      "someone\n",
      "{'Number': 'Sing', 'PronType': 'Ind'}\n",
      "----\n",
      "else\n",
      "{}\n",
      "----\n",
      "'s\n",
      "{}\n",
      "----\n",
      "life\n",
      "{'Number': 'Sing'}\n",
      "----\n",
      ".\n",
      "{'PunctType': 'Peri'}\n",
      "----\n",
      "Do\n",
      "{'VerbForm': 'Inf'}\n",
      "----\n",
      "n't\n",
      "{'Polarity': 'Neg'}\n",
      "----\n",
      "be\n",
      "{'VerbForm': 'Inf'}\n",
      "----\n",
      "trapped\n",
      "{'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "----\n",
      "by\n",
      "{}\n",
      "----\n",
      "dogma\n",
      "{'Number': 'Sing'}\n",
      "----\n",
      ",\n",
      "{'PunctType': 'Comm'}\n",
      "----\n",
      "which\n",
      "{}\n",
      "----\n",
      "is\n",
      "{'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "----\n",
      "living\n",
      "{'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "----\n",
      "with\n",
      "{}\n",
      "----\n",
      "the\n",
      "{'Definite': 'Def', 'PronType': 'Art'}\n",
      "----\n",
      "results\n",
      "{'Number': 'Plur'}\n",
      "----\n",
      "of\n",
      "{}\n",
      "----\n",
      "other\n",
      "{'Degree': 'Pos'}\n",
      "----\n",
      "people\n",
      "{'Number': 'Plur'}\n",
      "----\n",
      "'s\n",
      "{}\n",
      "----\n",
      "thinking\n",
      "{'Number': 'Sing'}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for token in doc:  \n",
    "    print(token.text)\n",
    "    print(token.morph.to_dict())       ## Prining the morphological features in dictionary format.\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{95: 4, 92: 6, 87: 5, 100: 5, 97: 3, 86: 2, 94: 4, 85: 3, 90: 1, 84: 1}\n",
      "  84. ADJ  : 1\n",
      "  85. ADP  : 3\n",
      "  86. ADV  : 2\n",
      "  87. AUX  : 5\n",
      "  90. DET  : 1\n",
      "  92. NOUN : 6\n",
      "  94. PART : 4\n",
      "  95. PRON : 4\n",
      "  97. PUNCT: 3\n",
      " 100. VERB : 5\n"
     ]
    }
   ],
   "source": [
    "# Counting the frequencies of different POS tags:\n",
    "POS_counts = doc.count_by(spacy.attrs.POS)\n",
    "print(POS_counts)\n",
    "\n",
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f'{k:{4}}. {doc.vocab[k].text:{5}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4062917326063685704: 1, 15308085513773655218: 5, 13927759927860985106: 2, 3822385049556375858: 2, 2593208677638477497: 2, 164681854541413346: 4, 9188597074677201817: 1, 14200088355797579614: 3, 13656873538139661788: 1, 1534113631682161808: 2, 74: 2, 12646065887601541794: 1, 1292078113972184607: 3, 17202369883303991778: 1, 15267657372422890137: 1, 783433942507015291: 2, 10554686591937588953: 1}\n",
      "74. POS : 2\n",
      "164681854541413346. RB  : 4\n",
      "783433942507015291. NNS : 2\n",
      "1292078113972184607. IN  : 3\n",
      "1534113631682161808. VBG : 2\n",
      "2593208677638477497. ,   : 2\n",
      "3822385049556375858. VBN : 2\n",
      "4062917326063685704. PRP$: 1\n",
      "9188597074677201817. VBP : 1\n",
      "10554686591937588953. JJ  : 1\n",
      "12646065887601541794. .   : 1\n",
      "13656873538139661788. PRP : 1\n",
      "13927759927860985106. VBZ : 2\n",
      "14200088355797579614. VB  : 3\n",
      "15267657372422890137. DT  : 1\n",
      "15308085513773655218. NN  : 5\n",
      "17202369883303991778. WDT : 1\n"
     ]
    }
   ],
   "source": [
    "# Counting the frequencies of different fine-grained tags:\n",
    "TAG_counts = doc.count_by(spacy.attrs.TAG)\n",
    "\n",
    "print(TAG_counts)\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f'{k}. {doc.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6a1604937e0b4484ace2bf41128e990c-0\" class=\"displacy\" width=\"5475\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Your</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">time</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">limited,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">so</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">n't</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">waste</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">living</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">someone</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">else</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">life.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">Do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">n't</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">be</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">trapped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">dogma,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">which</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">living</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">results</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">other</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">people</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">thinking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1275.0,2.0 1275.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-6\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-7\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-8\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,177.0 1615.0,177.0 1615.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,354.0 L1623.0,342.0 1607.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,89.5 2320.0,89.5 2320.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-10\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1960.0,354.0 L1968.0,342.0 1952.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-11\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2135.0,354.0 L2143.0,342.0 2127.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-12\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,2.0 2325.0,2.0 2325.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2325.0,354.0 L2333.0,342.0 2317.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-13\" stroke-width=\"2px\" d=\"M2520,352.0 C2520,89.5 3020.0,89.5 3020.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2520,354.0 L2512,342.0 2528,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-14\" stroke-width=\"2px\" d=\"M2695,352.0 C2695,177.0 3015.0,177.0 3015.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,354.0 L2687,342.0 2703,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-15\" stroke-width=\"2px\" d=\"M2870,352.0 C2870,264.5 3010.0,264.5 3010.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2870,354.0 L2862,342.0 2878,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-16\" stroke-width=\"2px\" d=\"M3045,352.0 C3045,264.5 3185.0,264.5 3185.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">agent</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3185.0,354.0 L3193.0,342.0 3177.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-17\" stroke-width=\"2px\" d=\"M3220,352.0 C3220,264.5 3360.0,264.5 3360.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3360.0,354.0 L3368.0,342.0 3352.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-18\" stroke-width=\"2px\" d=\"M3570,352.0 C3570,177.0 3890.0,177.0 3890.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3570,354.0 L3562,342.0 3578,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-19\" stroke-width=\"2px\" d=\"M3745,352.0 C3745,264.5 3885.0,264.5 3885.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3745,354.0 L3737,342.0 3753,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-20\" stroke-width=\"2px\" d=\"M3395,352.0 C3395,89.5 3895.0,89.5 3895.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3895.0,354.0 L3903.0,342.0 3887.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-21\" stroke-width=\"2px\" d=\"M3920,352.0 C3920,264.5 4060.0,264.5 4060.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4060.0,354.0 L4068.0,342.0 4052.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-22\" stroke-width=\"2px\" d=\"M4270,352.0 C4270,264.5 4410.0,264.5 4410.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4270,354.0 L4262,342.0 4278,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-23\" stroke-width=\"2px\" d=\"M4095,352.0 C4095,177.0 4415.0,177.0 4415.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4415.0,354.0 L4423.0,342.0 4407.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-24\" stroke-width=\"2px\" d=\"M4445,352.0 C4445,264.5 4585.0,264.5 4585.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4585.0,354.0 L4593.0,342.0 4577.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-25\" stroke-width=\"2px\" d=\"M4795,352.0 C4795,264.5 4935.0,264.5 4935.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4795,354.0 L4787,342.0 4803,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-26\" stroke-width=\"2px\" d=\"M4970,352.0 C4970,177.0 5290.0,177.0 5290.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4970,354.0 L4962,342.0 4978,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-27\" stroke-width=\"2px\" d=\"M4970,352.0 C4970,264.5 5110.0,264.5 5110.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5110.0,354.0 L5118.0,342.0 5102.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6a1604937e0b4484ace2bf41128e990c-0-28\" stroke-width=\"2px\" d=\"M4620,352.0 C4620,2.0 5300.0,2.0 5300.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6a1604937e0b4484ace2bf41128e990c-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5300.0,354.0 L5308.0,342.0 5292.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#   Visualizer  :   https://spacy.io/usage/visualizers\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigating the parse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your poss time NOUN []\n",
      "time nsubjpass limited VERB [Your]\n",
      "is auxpass limited VERB []\n",
      "limited ccomp waste VERB [time, is]\n",
      ", punct waste VERB []\n",
      "so advmod waste VERB []\n",
      "do aux waste VERB []\n",
      "n't neg waste VERB []\n",
      "waste ROOT waste VERB [limited, ,, so, do, n't, it, living, .]\n",
      "it dobj waste VERB []\n",
      "living advcl waste VERB [life]\n",
      "someone nmod life NOUN [else]\n",
      "else advmod someone PRON ['s]\n",
      "'s case else ADV []\n",
      "life dobj living VERB [someone]\n",
      ". punct waste VERB []\n",
      "Do aux trapped VERB []\n",
      "n't neg trapped VERB []\n",
      "be auxpass trapped VERB []\n",
      "trapped ROOT trapped VERB [Do, n't, be, by]\n",
      "by agent trapped VERB [dogma]\n",
      "dogma pobj by ADP [,, living]\n",
      ", punct dogma NOUN []\n",
      "which nsubj living VERB []\n",
      "is aux living VERB []\n",
      "living relcl dogma NOUN [which, is, with]\n",
      "with prep living VERB [results]\n",
      "the det results NOUN []\n",
      "results pobj with ADP [the, of]\n",
      "of prep results NOUN [thinking]\n",
      "other amod people NOUN []\n",
      "people poss thinking NOUN [other, 's]\n",
      "'s case people NOUN []\n",
      "thinking pobj of ADP [people]\n"
     ]
    }
   ],
   "source": [
    "# Get the children\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{living}\n"
     ]
    }
   ],
   "source": [
    "# Finding a verb with a subject\n",
    "from spacy.symbols import nsubj, VERB\n",
    "\n",
    "verbs = set()\n",
    "for possible_subject in doc:\n",
    "    if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "        verbs.add(possible_subject.head)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['limited', ',', 'so', 'do', \"n't\"]\n",
      "['it', 'living', '.']\n",
      "5\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#   Token.lefts and Token.rights attributes provide sequences of syntactic children that occur before and after the token.\n",
    "print([token.text for token in doc[8].lefts])  # ['limited', ',', 'so', 'do', \"n't\"]\n",
    "print([token.text for token in doc[8].rights])  # ['it', 'living', '.']\n",
    "print(doc[8].n_lefts)  # 5\n",
    "print(doc[8].n_rights)  # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your poss 0 0 ['time', 'limited', 'waste']\n",
      "time nsubjpass 1 0 ['limited', 'waste']\n",
      "is auxpass 0 0 ['limited', 'waste']\n",
      "limited ccomp 2 0 ['waste']\n"
     ]
    }
   ],
   "source": [
    "#   You can get a whole phrase by its syntactic head using the Token.subtree attribute.\n",
    "root = [token for token in doc if token.head == token][0]\n",
    "subject = list(root.lefts)[0]\n",
    "for descendant in subject.subtree:\n",
    "    assert subject is descendant or subject.is_ancestor(descendant)\n",
    "    print(descendant.text, descendant.dep_, descendant.n_lefts,\n",
    "            descendant.n_rights,\n",
    "            [ancestor.text for ancestor in descendant.ancestors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your PRON poss time\n",
      "time NOUN nsubjpass limited\n",
      "is AUX auxpass limited\n",
      "limited VERB ccomp waste\n",
      ", PUNCT punct waste\n",
      "so ADV advmod waste\n",
      "do AUX aux waste\n",
      "n't PART neg waste\n",
      "waste VERB ROOT waste\n",
      "it PRON dobj waste\n",
      "living VERB advcl waste\n",
      "someone PRON nmod life\n",
      "else ADV advmod someone\n",
      "'s PART case else\n",
      "life NOUN dobj living\n",
      ". PUNCT punct waste\n",
      "Do AUX aux trapped\n",
      "n't PART neg trapped\n",
      "be AUX auxpass trapped\n",
      "trapped VERB ROOT trapped\n",
      "by ADP agent trapped\n",
      "dogma NOUN pobj by\n",
      ", PUNCT punct dogma\n",
      "which PRON nsubj living\n",
      "is AUX aux living\n",
      "living VERB relcl dogma\n",
      "with ADP prep living\n",
      "the DET det results\n",
      "results NOUN pobj with\n",
      "of ADP prep results\n",
      "other ADJ amod people\n",
      "people NOUN poss thinking\n",
      "'s PART case people\n",
      "thinking NOUN pobj of\n"
     ]
    }
   ],
   "source": [
    "#   the .left_edge and .right_edge attributes can be especially useful, because they give you the first and last token of the subtree.\n",
    "span = doc[doc[4].left_edge.i : doc[4].right_edge.i+1]\n",
    "\n",
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(span)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net income --> $9.4 million\n",
      "the prior year --> $2.7 million\n",
      "Revenue --> twelve billion dollars\n",
      "a loss --> 1b\n"
     ]
    }
   ],
   "source": [
    "#   information extraction\n",
    "# Merge noun phrases and entities for easier analysis\n",
    "nlp.add_pipe(\"merge_entities\")  #https://spacy.io/api/pipeline-functions\n",
    "nlp.add_pipe(\"merge_noun_chunks\")\n",
    "\n",
    "TEXTS = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"MONEY\":\n",
    "            # We have an attribute and direct object, so check for subject\n",
    "            if token.dep_ in (\"attr\", \"dobj\"):\n",
    "                subj = [w for w in token.head.lefts if w.dep_ == \"nsubj\"]\n",
    "                if subj:\n",
    "                    print(subj[0], \"-->\", token)\n",
    "            # We have a prepositional object with a preposition\n",
    "            elif token.dep_ == \"pobj\" and token.head.dep_ == \"prep\":\n",
    "                print(token.head.head, \"-->\", token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('They', 'PRP'), ('think', 'VBP'), ('of', 'IN'), ('everything', 'NN'), ('in', 'IN'), ('terms', 'NNS'), ('of', 'IN'), ('money', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "\n",
    "text = \"They think of everything in terms of money\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "tag = nltk.pos_tag(tokens)\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  They/PRP\n",
      "  (mychunk think/VBP)\n",
      "  of/IN\n",
      "  (mychunk everything/NN)\n",
      "  in/IN\n",
      "  (mychunk terms/NNS)\n",
      "  of/IN\n",
      "  (mychunk money/NN))\n"
     ]
    }
   ],
   "source": [
    "patterns= \"\"\"mychunk:{<VB.*>*<NN.*>?}\"\"\"\n",
    "chunker = RegexpParser(patterns)\n",
    "output = chunker.parse(tag)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\w0rk5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\w0rk5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,912.0,168.0\" width=\"912px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"8.77193%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">European</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.38596%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"11.4035%\" x=\"8.77193%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">authorities</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.4737%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.14035%\" x=\"20.1754%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">fined</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.2456%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.01754%\" x=\"26.3158%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Google</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.8246%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.50877%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"35.0877%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.01754%\" x=\"36.8421%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">record</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40.3509%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.63158%\" x=\"43.8596%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">$</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"45.1754%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.38596%\" x=\"46.4912%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">5.1</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.6842%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.89474%\" x=\"50.8772%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">billion</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.8246%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.50877%\" x=\"58.7719%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">on</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"60.5263%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"9.64912%\" x=\"62.2807%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Wednesday</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.1053%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.38596%\" x=\"71.9298%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">for</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"74.1228%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.89474%\" x=\"76.3158%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">abusing</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80.2632%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.26316%\" x=\"84.2105%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">its</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"86.8421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.14035%\" x=\"89.4737%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">power</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.5439%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.38596%\" x=\"95.614%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">...</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">:</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.807%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "Tree('S', [Tree('GPE', [('European', 'JJ')]), ('authorities', 'NNS'), ('fined', 'VBD'), Tree('PERSON', [('Google', 'NNP')]), ('a', 'DT'), ('record', 'NN'), ('$', '$'), ('5.1', 'CD'), ('billion', 'CD'), ('on', 'IN'), ('Wednesday', 'NNP'), ('for', 'IN'), ('abusing', 'VBG'), ('its', 'PRP$'), ('power', 'NN'), ('...', ':')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK provides a classifier that has already been trained to recognize Named Entities.\n",
    "text = \"European authorities fined Google a record $5.1 billion on Wednesday for abusing its power...\"\n",
    "\n",
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European NORP\n",
      "Google ORG\n",
      "$5.1 billion MONEY\n",
      "Wednesday DATE\n"
     ]
    }
   ],
   "source": [
    "# SpaCy features an extremely fast statistical entity recognition system, that assigns labels to contiguous spans of tokens\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfb75dc7d96d332aeaa21ae2d7b833083e393049992869c7fba312a269a18e76"
  },
  "kernelspec": {
   "display_name": "text-mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
